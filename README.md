# Variational Inference on TrueSkill Model
## Summary
The original Trueskill paper from 2007 used message passing. Carl Rasmussen's assignment uses Gibbs sampling. In this project I will approximate posterior distributions with both gradient-based Hamiltonian Monte Carlo and gradient-based stochastic variational inference. <br />
The objective of this project is to implement and visualize a variant of the TrueSkill model using modern probabilistic inference techniques such as Hamiltonian Monte Carlo (HMC) and Stochastic Variational Inference (SVI). And to also explore and understand how the the posterior distribution changes when different scenarios are examined. 

## Tools and Libraries Used
- Python libraries: `torch`, `numpy`, `scipy`, `pandas`, `matplotlib`
- Optimization techniques: Hamiltonian Monte Carlo and Stochastic Variational Inference
- Visualization: Contour plots to represent joint distributions and posterior approximations

## Components
1. Posterior Analysis
* 
* 
3. 
